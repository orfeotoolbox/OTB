\chapter{Persistent filters}
\label{chapter:PersistentFilters}

\section{Introduction}

As presented in chapter~\ref{sec:StreamingAndThreading}, OTB has two
main mechanisms to handle efficiently large data: streaming allows to
process image piece-wise, and multi-threading allows to process
concurrently several pieces of one streaming block. Using these
concepts, one can easily write pixel-wise or neighborhood-based
filters and insert them into a pipeline which will be scalable with
respect to the input image size.

Yet, sometimes we need to compute global features on the whole image. One
example is to determine image mean and variance of the input image in
order to produce a centered and reduced image. The operation of
centering and reducing each pixel is fully compliant with streaming and
threading, but one has to first estimate the mean and variance of the
image. This first step requires to walk the whole image once, and
traditional streaming and multi-threading based filter architecture is
of no help here. 

This is because there is a fundamental difference between these two
operations: one supports streaming, and the other needs to perform
streaming. In fact we would like to stream the whole image piece by
piece through some filter that will collect and keep mean and variance
cumulants, and then synthetize theses cumulants to compute the final
mean and variance once the full image as been streamed. Each
stream would also benefit from parallel processing. This is exactly
what persistent filters are for.

\section{Architecture}

There are two main objects in the persistent filters framework. The
first is the \doxygen{otb}{PersistentImageFilter}, the second is the
\doxygen{otb}{PersistentFilterStreamingDecorator}.

\subsection{The persistent filter class}

The \doxygen{otb}{PersistentImageFilter} class is a regular
\doxygen{itk}{ImageToImageFilter}, with two additional pure virtual
methods: the \verb?Synthetize()? and the \verb?Reset()? methods.

Imagine that the \verb?GenerateData()? or
\verb?ThreadedGenerateData()? progressively computes some global
feature of the whole image, using some member of the class to store
intermediate results. The \verb?Synthetize()? is an additional method
which is designed to be called one the whole image has been processed,
in order to compute the final results from the intermediate
results. The \verb?Reset()? method is designed to allow the reset of
the intermediate results members so as to start a fresh processing.

Any sub-class of the \doxygen{otb}{PersistentImageFilter} can be used
as a regular \doxygen{itk}{ImageToImageFilter} (provided that both
\verb?Synthetize()? and \verb?Reset()? have been implemented, but the
real interest of these filters is to be used with the streaming
decorator class presented in the next section.

\subsection{The streaming decorator class}

The \doxygen{otb}{PersistentFilterStreamingDecorator} is a class
designed to be templated with subclasses of the
\doxygen{otb}{PersistentImageFilter}. It provides the mechanism to
stream the whole image through the templated filter, using a third
class called \doxygen{otb}{StreamingImageVirtualWriter}. When the
\verb?Update()? method is called on a
\doxygen{otb}{PersistentFilterStreamingDecorator}, a pipeline
plugging the templated subclass of the
\doxygen{otb}{PersistentImageFilter} to an instance of
\doxygen{otb}{StreamingImageVirtualWriter} is created. The latter is
then updated, and acts like a regular
\doxygen{otb}{ImageFileWriter} but it does not actually write
anything to the disk : streaming pieces are requested and immediately
discarded. The \doxygen{otb}{PersistentFilterStreamingDecorator}
also calls the \verb?Reset()? method at the beginning and the
\verb?Synthetize()? method at the end of the streaming
process. Therefore, it packages the whole mechanism for the use of a
\doxygen{otb}{PersistentImageFilter}:
\begin{enumerate}
\item Call the \verb?Reset()? method on the filter so as to reset any temporary
  results members,
\item Stream the image piece-wise through the filter,
\item Call the \verb?Synthetize()? method on the filter so as to
  compute the final results.
\end{enumerate}

There are some methods that allows to tune the behavior of the
\doxygen{otb}{StreamingImageVirtualWriter}, allowing to change the
image splitting methods (tiles or strips) or the size of the streams
with respect to some target available amount of memory. Please see the
class documentation for details. The instance of the
\doxygen{otb}{StreamingImageVirtualWriter} can be retrieved from the
\doxygen{otb}{PersistentFilterStreamingDecorator} through the
\verb?GetStreamer()? method.

Though the internal filter of the
\doxygen{otb}{PersistentFilterStreamingDecorator} can be accessed
through the \verb?GetFilter()? method, the class is often derived to
package the streaming-decorated filter and wrap the parameters setters
and getters.

\section{An end-to-end example}

This is an end-to-end example to compute the mean over a full image,
using a streaming and threading-enabled filter. Please note that only
specific details are explained here. For more general information on
how to write a filter, please refer to
section~\ref{chapter:WriteAFilter}, page~\pageref{chapter:WriteAFilter}.

\subsection{First step: writing a persistent filter}

The first step is to write a persistent mean image filter. We need to
include the appropriate header :

\begin{lstlisting}
#include "otbPersistentImageFilter.h"
\end{lstlisting}

Then, we declare the class prototype as follows:

\begin{lstlisting}
template<class TInputImage >
  class ITK_EXPORT PersistentMeanImageFilter :
    public PersistentImageFilter<TInputImage, TInputImage>
\end{lstlisting}

Since the output image will only be used for streaming purpose, we do
not need to declare different input and output template types.

In the \emph{private} section of the class, we will declare a member which
will be used to store temporary results, and a member which will be
used to store the final result.

\begin{lstlisting}
private:
  // Temporary results container
  std::vector<PixelType> m_TemporarySums;

  // Final result member
  double m_Mean;
\end{lstlisting}

Next, we will write the \verb?Reset()? method implementation in the
\emph{protected} section of the class. Proper allocation of the
temporary results container with respect to the number of threads is
handled here.


\begin{lstlisting}
protected:
  virtual void Reset()
  {
  // Retrieve the number of threads
  unsigned int numberOfThreads = this->GetNumberOfThreads();

  // Reset the temporary results container
  m_TemporarySums = std::vector<PixelType>(numberOfThreads,
                                           itk::NumericTraits<PixelType>::Zero);

  // Reset the final result
  m_Mean = 0.;
  }
\end{lstlisting}

Now, we need to write the \verb?ThreadedGenerateData()? methods (also
in the \emph{protected} section), were
temporary results will be computed for each piece of stream.

\begin{lstlisting}
virtual void ThreadedGenerateData(const RegionType&
                                  outputRegionForThread, int threadId)
{
// Enable progress reporting
itk::ProgressReporter(this,threadId,outputRegionForThread.GetNumberOfPixels());

// Retrieve the input pointer
InputImagePointer inputPtr = const_cast<TInputImage *>(this->GetInput());

// Declare an iterator on the region
itk::ImageRegionConstIteratorWithIndex<TInputImage> it(inputPtr,
outputRegionForThread);

// Walk the region of the image with the iterator
for (it.GoToBegin(); !it.IsAtEnd(); ++it, progress.CompletedPixel())
  {
  // Retrieve pixel value
  const PixelType& value = it.Get();

  // Update temporary results for the current thread
  m_TemporarySums[threadId]+= value;
}

\end{lstlisting}

Last, we need to define the \verb?Synthetize()? method (still in the
\emph{protected} section), which will yield the final results:

\begin{lstlisting}
virtual void Synthetize()
{
// For each thread
for(unsigned int threadId = 0; threadId <this->GetNumberOfThreads();++threadId)
  {
  // Update final result
  m_Mean+=m_TemporarySums[threadId];
} 

// Complete calculus by dividing by the total number of pixels:
unsigned int nbPixels =
this->GetInput()->GetLargestPossibleRegion().GetNumberOfPixels();

if(nbPixels!=0)
  {
  m_Mean/=nbPixels;
  }  
}
\end{lstlisting}

\subsection{Second step: Decorating the filter and using it}

Now, to use the filter, one only has to decorate it with the
\doxygen{otb}{PersistentFilterStreamingDecorator}. First step is
to include the appropriate header:

\begin{lstlisting}
#include "otbPersistentMeanImageFilter.h"
#include "otbPersistentFilterStreamingDecorator.h"
\end{lstlisting}

Then, we decorate the filter with some typedefs:

\begin{lstlisting}
typedef otb::PersistentMeanImageFilter<ImageType>
  PersitentMeanFilterType;
typedef otb::PersistentFilterStreamingDecorator
  < PersitentMeanFilterType> StreamingMeanFilterType;
\end{lstlisting}

Now, the decorated filter can be used like any standard filter:

\begin{lstlisting}
StreamingMeanFilterType::Pointer filter =
  StreamingMeanFilterType::New();

filter->SetInput(reader->GetOutput());
filter->Update();
\end{lstlisting}

\subsection{Third step: one class to rule them all}

It is often convenient to avoid the few typedefs of the previous
section by deriving a new class from the decorated filter:

\begin{lstlisting}
template<class TInputImage >
  class ITK_EXPORT StreamingMeanImageFilter :
    public PersistentFilterStreamingDecorator<
           PersistentImageFilter<TInputImage, TInputImage> >
\end{lstlisting}

This also allows to redefine setters and getters for parameters,
avoiding to call the \verb?GetFilter()? method to set them.
